import glob
import re
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

train_neg_text_files=glob.glob("C:/Users/hys35/Desktop/yelp_dataset-2/aclImdb_v1 (1).tar/aclImdb/train/neg/*.txt")
train_pos_text_files=glob.glob("C:/Users/hys35/Desktop/yelp_dataset-2/aclImdb_v1 (1).tar/aclImdb/train/pos/*.txt")
test_neg_text_files=glob.glob("C:/Users/hys35/Desktop/yelp_dataset-2/aclImdb_v1 (1).tar/aclImdb/test/neg/*.txt")
test_pos_text_files=glob.glob("C:/Users/hys35/Desktop/yelp_dataset-2/aclImdb_v1 (1).tar/aclImdb/test/pos/*.txt")

text_list=[]
for text_files in [train_neg_text_files, train_pos_text_files, test_neg_text_files, test_pos_text_files]:
    for text in text_files:
        text0 = open(text,'r',encoding="utf8")
        message=text0.read()
        text0.close()
        text_list.append(message)

text_list=[re.sub(r'[^A-Za-z0-9 ]+', '', s) for s in text_list] # Keep only alphanumeric and space.
    

vectorizer = CountVectorizer(stop_words='english')

X = vectorizer.fit_transform(text_list)


# vectorizer.get_feature_names()

Y=[]
for text_files in [train_neg_text_files, train_pos_text_files, test_neg_text_files, test_pos_text_files]:
    for i in range(len(text_files)):
        Y.append(float(text_files[i][-5]))





# For yelp dataset

dataset_review= pd.read_json(r'C:\Users\hys35\Desktop\yelp_dataset-2\yelp_academic_dataset_review.json', lines=True, chunksize=10000)

chunk_list = []
for chunk in dataset_review:
    chunk_list.append(chunk)
df_review = pd.concat(chunk_list, ignore_index=True)

df_review["text"].tolist()
df_review["stars"].tolist()

yelp_texts=[re.sub(r'[^A-Za-z0-9 ]+', '', s) for s in df_review["text"]]

L=[len(s) for s in yelp_texts]

[i for i, j in enumerate(L) if j == 0]
Empty=[i for i, j in enumerate(L) if j == 0]

yelp_texts=[element for i, element in enumerate(yelp_texts) if i not in Empty]
Y_yelp=[float(i) for i in df_review["stars"].tolist()]


X_yelp=vectorizer.fit_transform(yelp_texts)
Y_yelp=[element for i, element in enumerate(Y_yelp) if i not in Empty]
